path:
  run_name: colossal-rooster
  dataset_root_dir: D:\\datasets\\imagenet_processed_256
  tb_log_dir: runs
  checkpoint_save_path: weights

model:
  __class_fullname__: source.models.AlexNet
  n_classes: 1000
  in_channels: 3

training:
  start_from_this_ckpt: weights\\colossal-rooster\\alexnet_45_0.275_full.pt
  n_epochs: 90
  save_every_epoch: 1
  device: cuda:0
  batch_size: 128
  pin_memory: true
  dataloader_num_workers: 16
  
# Page 6. Section 5.
optimizer:
  __class_fullname__: torch.optim.SGD
  lr: 0.01
  weight_decay: 0.0005
  momentum: 0.9

criterion:
  __class_fullname__: torch.nn.CrossEntropyLoss

scheduler:
  __class_fullname__: torch.optim.lr_scheduler.ReduceLROnPlateau
  mode: min

augmentations:
  train:
    transform:
      __class_fullname__: Compose
      transforms:

        # Page 2. Section 2.
        # ImageNet consists of variable-resolution images, while our
        # system requires a constant input dimensionality. Therefore,
        # we down-sampled the images to a fixed resolution of 256×256.
        # Given a rectangular image, we first rescaled the image such
        # that the shorter side was of length 256, and then cropped
        # out the central 256×256 patch from the resulting image.

        # NOTE: Resizing-like transformations turned off since i
        # used `preprocess_imagenet.py` script that do it offline.

        # - __class_fullname__: albumentations.SmallestMaxSize
        #   max_size: 256
        # - __class_fullname__: albumentations.CenterCrop
        #   height: 256
        #   width: 256
        #   p: 1.0
        
        # Page 5. Section 4.1.
        # The first form of data augmentation consists of generating
        # image translations and horizontal reflections. We do this
        # by extracting random 224 × 224 patches (and their horizontal
        # reflections) from the 256×256 images and training our network
        # on these extracted patches
        - __class_fullname__: albumentations.augmentations.crops.transforms.RandomResizedCrop
          height: 224
          width: 224
        - __class_fullname__: albumentations.augmentations.geometric.transforms.HorizontalFlip

        # Page 5. Section 4.1.
        # Specifically, we perform PCA on the set of RGB pixel values
        # throughout the ImageNet training set...
        - __class_fullname__: albumentations.augmentations.transforms.FancyPCA

        # Page 2. Section 2.
        # "We did not pre-process the images in any other way, except
        # for subtracting the mean activity over the training set from
        # each pixel. So we trained our network on the (centered) raw
        # RGB values of the pixels."
        - __class_fullname__: albumentations.augmentations.transforms.Normalize
          always_apply: true
          max_pixel_value: 1.0
          mean:
            - 123.675
            - 116.28
            - 103.53
          std:
            - 1
            - 1
            - 1
        - __class_fullname__: albumentations.pytorch.transforms.ToTensorV2
          always_apply: true
  val:
    transform:
      __class_fullname__: Compose
      transforms:
        # Page 2. Section 2.
        # ImageNet consists of variable-resolution images, while our
        # system requires a constant input dimensionality. Therefore,
        # we down-sampled the images to a fixed resolution of 256×256.
        # Given a rectangular image, we first rescaled the image such
        # that the shorter side was of length 256, and then cropped
        # out the central 256×256 patch from the resulting image.

        # So, they used the same preprocessing for the validation
        # images, but after they used so-called ten-crop transform.
        # NOTE: THIS 10-crop transform is used inside training loop.

        # NOTE: Resizing-like transformations turned off since i
        # used `preprocess_imagenet.py` script that do it offline.

        # - __class_fullname__: albumentations.SmallestMaxSize
        #   max_size: 256
        # - __class_fullname__: albumentations.CenterCrop
        #   height: 256
        #   width: 256
        #   p: 1.0

        # Page 2. Section 2.
        # "We did not pre-process the images in any other way, except
        # for subtracting the mean activity over the training set from
        # each pixel. So we trained our network on the (centered) raw
        # RGB values of the pixels."
        - __class_fullname__: albumentations.augmentations.transforms.Normalize
          always_apply: true
          max_pixel_value: 1.0
          mean:
            - 123.675
            - 116.28
            - 103.53
          std:
            - 1
            - 1
            - 1
        - __class_fullname__: albumentations.pytorch.transforms.ToTensorV2
          always_apply: true
